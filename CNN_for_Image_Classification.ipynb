{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport keras\nimport pandas as pd\nfrom keras.models import Sequential \nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom keras.utils import np_utils\nimport cv2\nimport os\nimport glob","metadata":{"execution":{"iopub.status.busy":"2022-03-23T22:52:04.680591Z","iopub.execute_input":"2022-03-23T22:52:04.680843Z","iopub.status.idle":"2022-03-23T22:52:10.154323Z","shell.execute_reply.started":"2022-03-23T22:52:04.680773Z","shell.execute_reply":"2022-03-23T22:52:10.153557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This project involves creating a CNN classifier for classifying almost 60,000 images into 10 class objects including lion, rocket, tank, flower, streetcar, deer, plane, bird, car, truck. The training and testing data were acquired from the following competition:\n\nhttps://www.kaggle.com/competitions/stat940-winter-2022-dc1","metadata":{}},{"cell_type":"markdown","source":"# Step 1: Loading Data","metadata":{}},{"cell_type":"code","source":"#Loading Training Labels\n\ny_train= pd.read_csv('/kaggle/input/stat940-winter-2022-dc1/train_labels.csv')\ndel y_train['id']\n\n#y_train.describe()\ny_train","metadata":{"execution":{"iopub.status.busy":"2022-03-23T22:53:17.942238Z","iopub.execute_input":"2022-03-23T22:53:17.942929Z","iopub.status.idle":"2022-03-23T22:53:17.987622Z","shell.execute_reply.started":"2022-03-23T22:53:17.942894Z","shell.execute_reply":"2022-03-23T22:53:17.986916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"i.e The training labels(y_train) are loaded by reading the 'train_labels.csv'.\n","metadata":{}},{"cell_type":"markdown","source":"                i.e The training data(x_train) is organizaed, tested, and loaded.\n\n*Problem: The Output labels(Y_train) are organized but the input data(.jpg images) for both the test(x_test) and training(x_train) are not organized in the folder. This could lead to incorrect matching between the training input (x_train) and the training output (y_train) which would thus cause a major problem when training the model.\n\nsolutions suggested:\n\na. Download the training data locally, reorganize the data, upload the data, read the data using the imread() function, and then append the data to form a list. Finally, store the data in a variable and convert it into a numpy array using \"np.array(Variable)\". \n\nb. Read the images in the directory sequentially through a f-string and then append the data to form a list. Perform this procedure for both the testing data(x_test) and the training data(x_train).\n\nOption chosen: Option b. Our goal is to read the images sequentially and then store them in a variable. Downloading the whole data and then reorganizing all the data for a future upload would be time expensive and unnecessary especially when our goal is to just fetch/read the data in sequence to store in a list. This list could then be converted into a numpy array for using it as inputs for the model.","metadata":{}},{"cell_type":"code","source":"#Loading Training Data\n\nx_train=[]\n\n#String Formatting\n\nfor a in range(50000):\n    img= cv2.imread(f'/kaggle/input/stat940-winter-2022-dc1/train/train/{a}.jpg')\n    x_train.append(img)\n\nx_train= np.array(x_train)\nprint(x_train.shape)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-03-23T22:53:26.23268Z","iopub.execute_input":"2022-03-23T22:53:26.232934Z","iopub.status.idle":"2022-03-23T22:55:59.53584Z","shell.execute_reply.started":"2022-03-23T22:53:26.232907Z","shell.execute_reply":"2022-03-23T22:55:59.534934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The shape of the training data(x_train) is (50000,32,32,3) where 50000 represents the number of images, the two 32s represent the size of the image(32*32), and the 3 represents the RGB color channels. ","metadata":{}},{"cell_type":"code","source":"plt.figure()                                      # create new figure\nfig_size = [20, 20]                               # specify figure size\nplt.rcParams[\"figure.figsize\"] = fig_size         # set figure size\n\n#Plot first 10 train image of dataset\nfor i in range(0,10):                          \n    ax = plt.subplot(10, 10, i+1)                  # Specify the i'th subplot of a 10*10 grid\n    img = x_train[i,:,:,:]                        # Choose i'th image from train data\n    ax.get_xaxis().set_visible(False)             # Disable plot axis.\n    ax.get_yaxis().set_visible(False)\n    plt.imshow(img)\n    \nplt.show()\n\n#NOTE: This portion of the code for printing training images was taken from a tutorial from \n#the STAT 940 course at the University of Waterloo.","metadata":{"execution":{"iopub.status.busy":"2022-03-23T23:18:54.966672Z","iopub.execute_input":"2022-03-23T23:18:54.966948Z","iopub.status.idle":"2022-03-23T23:18:55.050439Z","shell.execute_reply.started":"2022-03-23T23:18:54.966877Z","shell.execute_reply":"2022-03-23T23:18:55.049565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After reading the images in the right order and then storing those images in \"x_train\" variable, the images were in the right order with respect to the training \"y_train\" labels. Thus, the training data \"x_train\" was ready for the model.","metadata":{}},{"cell_type":"code","source":"#Loading Testing Data\n\nx_test=[]\n\n#String Formatting\n\nfor a in range(10000):\n    img1= cv2.imread(f'/kaggle/input/stat940-winter-2022-dc1/test/test/{a}.jpg')\n    x_test.append(img1)\n\nx_test= np.array(x_test)\nprint(x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T00:31:26.421165Z","iopub.execute_input":"2022-02-13T00:31:26.421522Z","iopub.status.idle":"2022-02-13T00:31:35.269577Z","shell.execute_reply.started":"2022-02-13T00:31:26.421491Z","shell.execute_reply":"2022-02-13T00:31:35.268599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"                    i.e The test data(x_test) is organized, read, and loaded.","metadata":{}},{"cell_type":"markdown","source":"The shape of the test data(x_test) is (10000,32,32,3) where 10000 represents the number of images, the two 32s represent the size of the image(32*32), and the 3 represents the RGB color channels. ","metadata":{}},{"cell_type":"markdown","source":"# Step 2: Setting Parameters","metadata":{}},{"cell_type":"code","source":"batch_size= 256\nnum_classes= 10\nepochs= 50","metadata":{"execution":{"iopub.status.busy":"2022-02-13T01:10:41.993422Z","iopub.execute_input":"2022-02-13T01:10:41.993732Z","iopub.status.idle":"2022-02-13T01:10:41.999758Z","shell.execute_reply.started":"2022-02-13T01:10:41.993701Z","shell.execute_reply":"2022-02-13T01:10:41.998433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"i.e A batch size of 256, 50 epochs and 10 classes are defined for the model.","metadata":{}},{"cell_type":"markdown","source":"# Step 3: Preparing Data","metadata":{}},{"cell_type":"code","source":"\nx_train= x_train.astype('float32') #type casting \nx_test= x_test.astype('float32')\n\nx_train /=255 # Normalization of data: Divide by 255\nx_test /=255","metadata":{"execution":{"iopub.status.busy":"2022-02-13T00:43:14.004069Z","iopub.execute_input":"2022-02-13T00:43:14.004634Z","iopub.status.idle":"2022-02-13T00:43:14.341301Z","shell.execute_reply.started":"2022-02-13T00:43:14.004602Z","shell.execute_reply":"2022-02-13T00:43:14.340155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"i.e The data samples are type-casted and normalized.","metadata":{}},{"cell_type":"code","source":"y_train= np_utils.to_categorical(y_train, num_classes) #one-hot encoding: Organizing the labels","metadata":{"execution":{"iopub.status.busy":"2022-02-13T00:43:17.073346Z","iopub.execute_input":"2022-02-13T00:43:17.074324Z","iopub.status.idle":"2022-02-13T00:43:17.082004Z","shell.execute_reply.started":"2022-02-13T00:43:17.074287Z","shell.execute_reply":"2022-02-13T00:43:17.081046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4: CNN Model Setup","metadata":{"execution":{"iopub.status.busy":"2022-02-12T04:47:56.692914Z","iopub.execute_input":"2022-02-12T04:47:56.693279Z","iopub.status.idle":"2022-02-12T04:47:56.720848Z","shell.execute_reply.started":"2022-02-12T04:47:56.693181Z","shell.execute_reply":"2022-02-12T04:47:56.719821Z"}}},{"cell_type":"code","source":"model = Sequential()\n\n#layer 1: 32 Kernels with 5*5 size and relu activation\n\nmodel.add(Conv2D(128, (5,5), padding='same', activation= 'relu', input_shape=x_train.shape[1:]))\n\n#layer 2: Max pooling with pool size 2*2\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n#layer 3: Dropout Layer with a rate 0.25(randomly selected neurons are ignored)\n\nmodel.add(Dropout(0.25))\n\n#layer 4\n\nmodel.add(Conv2D(128, (2,2), padding='same', activation= 'relu', input_shape=x_train.shape[1:]))\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Dropout(0.25))\n\n#Max Pooling Layer\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(150, activation ='relu'))\n\n#model.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation = 'softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-13T00:56:59.678876Z","iopub.execute_input":"2022-02-13T00:56:59.679361Z","iopub.status.idle":"2022-02-13T00:56:59.804414Z","shell.execute_reply.started":"2022-02-13T00:56:59.679285Z","shell.execute_reply":"2022-02-13T00:56:59.803358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x_train,y_train, batch_size= batch_size, epochs= epochs)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-13T01:10:59.769723Z","iopub.execute_input":"2022-02-13T01:10:59.77001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 5: Prediction of Test Labels","metadata":{}},{"cell_type":"code","source":"y_testB= model.predict(x_test)\ny_test= np.argmax(y_testB, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T23:08:08.860652Z","iopub.execute_input":"2022-02-11T23:08:08.860998Z","iopub.status.idle":"2022-02-11T23:08:09.597191Z","shell.execute_reply.started":"2022-02-11T23:08:08.860944Z","shell.execute_reply":"2022-02-11T23:08:09.596384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model predict the output labels based on the labels. This output is stored in y_testB but the output has to be converted from one-hot encoding to a form that is similar to the orginal data with classification ranging from 0 to 9. Thus, argmax is used to return the outputs back to it's original form.","metadata":{}},{"cell_type":"markdown","source":"# Step 6: Exporting Predicted Labels to CSV File","metadata":{}},{"cell_type":"code","source":"res = pd.DataFrame(y_test)\n#res.index = x_test.index # its important for comparison\nres.columns = [\"label\"]\nres.to_csv(\"test_results5.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-11T23:08:17.961193Z","iopub.execute_input":"2022-02-11T23:08:17.961964Z","iopub.status.idle":"2022-02-11T23:08:17.994876Z","shell.execute_reply.started":"2022-02-11T23:08:17.961925Z","shell.execute_reply":"2022-02-11T23:08:17.994007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A dataframe \"res\" is created and y_test is stored in it. The \"res\" dataframe is then converted to a .csv file.","metadata":{}}]}